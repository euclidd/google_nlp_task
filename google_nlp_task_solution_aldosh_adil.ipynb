{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/aldos/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to /home/aldos/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import logging\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "\n",
    "import spacy\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from joblib import dump, load\n",
    "\n",
    "from num2words import num2words\n",
    "\n",
    "stopwords = set(stopwords.words('english'))\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# punct = '[!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~’\\\"—“”•]'\n",
    "punct = '[!\\\"#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~’—“”•]'\n",
    "\n",
    "logging.basicConfig(level=logging.INFO, force=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## All-in-one preprocess function \n",
    "\n",
    "\n",
    "### The process of data preparation is divided into 3 main parts\n",
    "#### Tokenization: \n",
    "  Text into individual tokens, which are mostly words (some combinations of words and/ or numbers are present)\n",
    "#### Removing stopwords and punctuation:\n",
    "  We gotta get rid of all the words and symbold that don't add a lot of meaning to the text\n",
    "#### Lemmatization:\n",
    "  Probably the most interesting part: we transform words into their normal form, so that all the words from the list ['run', 'running', 'runs'] becomes 'run'. This allows for better generalization as all these three form have almost the same meaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(text: str) -> str:\n",
    "    \"\"\"\n",
    "    Preprocess text:\n",
    "    1) tokenize lowercase text\n",
    "    2) exclude all the stopwords and punctuation\n",
    "    3) get lemmas of the tokens\n",
    "    \n",
    "    :text str: string of raw text\n",
    "    :returns str: string of preprocessed text\n",
    "    \"\"\"\n",
    "    doc = \" \".join([token for token in word_tokenize(text.lower())\n",
    "                        if token not in stopwords and token not in punct])\n",
    "    \n",
    "    result = [token.lemma_ for token in nlp(doc)] \n",
    "    \n",
    "    return \" \".join(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### !!! A part of numerical data appears to be in some kind of strange format so this function throws an error at some point while preprocessing data. Further analysis of numerical data types should be conducted to understand the problem and solve it. !!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def preprocess_text_with_nums(text: str) -> str:\n",
    "#     \"\"\"\n",
    "#     Preprocess text:\n",
    "#     1) tokenize lowercase text\n",
    "#     2) turn numbers into their textual representation\n",
    "#     3) exclude all the stopwords and punctuation\n",
    "#     4) get lemmas of the tokens\n",
    "    \n",
    "#     :text str: string of raw text\n",
    "#     :returns str: string of preprocessed text\n",
    "#     \"\"\"\n",
    "    \n",
    "#     doc = []\n",
    "#     for token in word_tokenize(text.lower()):\n",
    "#         if token.isdigit():\n",
    "#             try:\n",
    "#                 token = \" \".join([word for word in re.sub(punct, ' ', num2words(token)).split()\n",
    "#                                       if word not in punct and word not in stopwords])\n",
    "#                 doc.append(token)\n",
    "            \n",
    "#             except Exception:\n",
    "#                 logging.exception(\"An exception in tokenization process...\")\n",
    "#         else:\n",
    "#             if token not in punct and token not in stopwords:\n",
    "#                 doc.append(token)\n",
    "    \n",
    "#     # make a string\n",
    "#     doc = \" \".join(doc)\n",
    "    \n",
    "#     # take lemmas of tokens\n",
    "#     result = [token.lemma_ for token in nlp(doc)] \n",
    "    \n",
    "#     return \" \".join(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = \"All work and no play makes Jack a dull boy, all work and no play in 1984\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# preprocess_text_with_nums(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 13.1 ms, sys: 328 µs, total: 13.4 ms\n",
      "Wall time: 12.1 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'work play make jack dull boy work play 1984'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "preprocess_text(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Load the first dataset\n",
    "df1 = pd.read_csv('data/articles1.csv')\n",
    "df1.drop('Unnamed: 0', axis=1, inplace=True)\n",
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess contents of a content column (hehe) and store it as a new one\n",
    "df1_clean_column = df1.content.apply(lambda x: preprocess_text(x))\n",
    "df1['clear_text'] = df1_clean_column\n",
    "df1.to_csv('data/articles1_clean.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the second dataframe\n",
    "df2 = pd.read_csv('data/articles2.csv')\n",
    "df2.drop('Unnamed: 0', axis=1, inplace=True)\n",
    "print(f\"df2 shape: {df2.shape}\")\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess contents of a content column (hehe) and store it as a new one\n",
    "df2_clear_column = df2.content.apply(lambda x: preprocess_text(x))\n",
    "df2['clear_text'] = df2_clear_column\n",
    "df2.to_csv('data/articles2_clean.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the third dataframe\n",
    "df3 = pd.read_csv('data/articles3.csv')\n",
    "df3.drop('Unnamed: 0', axis=1, inplace=True)\n",
    "print(df3.shape)\n",
    "df3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleanse text in articles3.csv and persist the new version on disk\n",
    "df3_clear_column = df3.content.apply(lambda x: preprocess_text(x))\n",
    "df3['clear_text'] = df3_clear_column\n",
    "df3.to_csv('data/articles3_clean.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge 3 cleaned dataframes into one and check the result\n",
    "df_full = pd.concat([df1, df2, df3], axis=0)\n",
    "print(f\"Resulting DataFrame shape: {df_full.shape}\")\n",
    "df_full.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Persist full dataframe on disk\n",
    "df_full.to_csv('data/articles_full_cleaned.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(142570, 11)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>publication</th>\n",
       "      <th>author</th>\n",
       "      <th>date</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>url</th>\n",
       "      <th>content</th>\n",
       "      <th>clear_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>17283</td>\n",
       "      <td>House Republicans Fret About Winning Their Hea...</td>\n",
       "      <td>New York Times</td>\n",
       "      <td>Carl Hulse</td>\n",
       "      <td>2016-12-31</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>WASHINGTON  —   Congressional Republicans have...</td>\n",
       "      <td>washington congressional republican new fear c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>17284</td>\n",
       "      <td>Rift Between Officers and Residents as Killing...</td>\n",
       "      <td>New York Times</td>\n",
       "      <td>Benjamin Mueller and Al Baker</td>\n",
       "      <td>2017-06-19</td>\n",
       "      <td>2017.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>After the bullet shells get counted, the blood...</td>\n",
       "      <td>bullet shell get count blood dry votive candle...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>17285</td>\n",
       "      <td>Tyrus Wong, ‘Bambi’ Artist Thwarted by Racial ...</td>\n",
       "      <td>New York Times</td>\n",
       "      <td>Margalit Fox</td>\n",
       "      <td>2017-01-06</td>\n",
       "      <td>2017.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>When Walt Disney’s “Bambi” opened in 1942, cri...</td>\n",
       "      <td>walt disney bambi open 1942 critic praise spar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>17286</td>\n",
       "      <td>Among Deaths in 2016, a Heavy Toll in Pop Musi...</td>\n",
       "      <td>New York Times</td>\n",
       "      <td>William McDonald</td>\n",
       "      <td>2017-04-10</td>\n",
       "      <td>2017.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Death may be the great equalizer, but it isn’t...</td>\n",
       "      <td>death may great equalizer necessarily evenhand...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>17287</td>\n",
       "      <td>Kim Jong-un Says North Korea Is Preparing to T...</td>\n",
       "      <td>New York Times</td>\n",
       "      <td>Choe Sang-Hun</td>\n",
       "      <td>2017-01-02</td>\n",
       "      <td>2017.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SEOUL, South Korea  —   North Korea’s leader, ...</td>\n",
       "      <td>seoul south korea north korea leader kim say s...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0     id                                              title  \\\n",
       "0           0  17283  House Republicans Fret About Winning Their Hea...   \n",
       "1           1  17284  Rift Between Officers and Residents as Killing...   \n",
       "2           2  17285  Tyrus Wong, ‘Bambi’ Artist Thwarted by Racial ...   \n",
       "3           3  17286  Among Deaths in 2016, a Heavy Toll in Pop Musi...   \n",
       "4           4  17287  Kim Jong-un Says North Korea Is Preparing to T...   \n",
       "\n",
       "      publication                         author        date    year  month  \\\n",
       "0  New York Times                     Carl Hulse  2016-12-31  2016.0   12.0   \n",
       "1  New York Times  Benjamin Mueller and Al Baker  2017-06-19  2017.0    6.0   \n",
       "2  New York Times                   Margalit Fox  2017-01-06  2017.0    1.0   \n",
       "3  New York Times               William McDonald  2017-04-10  2017.0    4.0   \n",
       "4  New York Times                  Choe Sang-Hun  2017-01-02  2017.0    1.0   \n",
       "\n",
       "   url                                            content  \\\n",
       "0  NaN  WASHINGTON  —   Congressional Republicans have...   \n",
       "1  NaN  After the bullet shells get counted, the blood...   \n",
       "2  NaN  When Walt Disney’s “Bambi” opened in 1942, cri...   \n",
       "3  NaN  Death may be the great equalizer, but it isn’t...   \n",
       "4  NaN  SEOUL, South Korea  —   North Korea’s leader, ...   \n",
       "\n",
       "                                          clear_text  \n",
       "0  washington congressional republican new fear c...  \n",
       "1  bullet shell get count blood dry votive candle...  \n",
       "2  walt disney bambi open 1942 critic praise spar...  \n",
       "3  death may great equalizer necessarily evenhand...  \n",
       "4  seoul south korea north korea leader kim say s...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_full = pd.read_csv('data/articles_full_cleaned.csv')\n",
    "print(df_full.shape)\n",
    "df_full.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### It appears that some articles have urls which can be used for boosting ranking as described in the paper \"The Anatomy of a Large-Scale Hypertextual Web Search Engine\". WIll definetely implement it in future works on this project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create TF-IDF vectorizer and fit it whole corpora\n",
    "\n",
    "def initialize_tfidf(data, column_name):\n",
    "    \n",
    "    tfidf = TfidfVectorizer()\n",
    "    tfidf_matrix = tfidf.fit_transform(data[column_name])\n",
    "    \n",
    "    return tfidf, tfidf_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tfidf, tfidf_matrix = initialize_tfidf(df_full, 'clear_text')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model and reverse indexed matrix\n",
    "\n",
    "def save_models(tfidf, tfidf_matrix):\n",
    "    \n",
    "    filename = 'models/tfidf.sav'\n",
    "    dump(tfidf, filename)\n",
    "\n",
    "    filename = 'models/tfidf_matrix.sav'\n",
    "    dump(tfidf_matrix, filename)\n",
    "\n",
    "save_models(tfidf, tfidf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the models so we don't need to recompute the tf-idf values\n",
    "\n",
    "tfidf = load('models/tfidf.sav')\n",
    "tfidf_matrix = load('models/tfidf_matrix.sav')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_query_scores(tfidf, tfidf_matrix, query):\n",
    "    \"\"\"\n",
    "    Get top 10 docs for each word\n",
    "    \"\"\"\n",
    "    query_scoring = {}\n",
    "    for word in preprocess_text(query).split():\n",
    "\n",
    "        word_id = tfidf.vocabulary_[word]\n",
    "        new_vec = tfidf_matrix[:, word_id]\n",
    "        \n",
    "        # Argsort returns list of indicies for elements\n",
    "        # from the original list in ascending order\n",
    "        # e.g. original = [3, 2, 1]\n",
    "        # original.argsort() = [3, 1, 0] <- one is the \n",
    "        # smallest element and its index in original == 3\n",
    "        \n",
    "        top_docs = new_vec.toarray()[:, 0].argsort()[:-11:-1]\n",
    "\n",
    "        query_scoring[word] = top_docs.tolist()\n",
    "    \n",
    "        \n",
    "    return query_scoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 296 ms, sys: 0 ns, total: 296 ms\n",
      "Wall time: 295 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Get most relevant documents from tf-idf matrix and \n",
    "# create a list of top documents (max 10 for each word in a query)\n",
    "current_query = 'work desk'\n",
    "query_scoring = get_query_scores(tfidf, tfidf_matrix, current_query)\n",
    "\n",
    "top_docs = []\n",
    "for k, v in query_scoring.items():\n",
    "    top_docs.extend(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_cosine_sim(tfidf, tfidf_matrix, top_docs, query):\n",
    "    \"\"\"\n",
    "    Transform query into a vector of len(vocabulary) dim \n",
    "    and calculate cosine similarity between this vector and tf-idf suggestions\n",
    "    \"\"\"\n",
    "    query_vec = tfidf.transform(['work desk'])\n",
    "    cos_sim_scores = {doc_id: cosine_similarity(\n",
    "                        query_vec, tfidf_matrix[doc_id]).flatten()[0]\n",
    "                          for doc_id in top_docs}\n",
    "    \n",
    "    return cos_sim_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 37.2 ms, sys: 298 µs, total: 37.5 ms\n",
      "Wall time: 34.7 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "cos_sim_scores = calc_cosine_sim(tfidf, tfidf_matrix, top_docs, current_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get top 5 docs by cosine similarity value\n",
    "def get_top_docs(cos_sim_scores):\n",
    "    return [doc[0] for doc in sorted(cos_sim_scores.items(), key=lambda x:x[1], reverse=True)[:5]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 10 µs, sys: 1e+03 ns, total: 11 µs\n",
      "Wall time: 13.1 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "top_5_docs = get_top_docs(cos_sim_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 8.56 ms, sys: 543 µs, total: 9.1 ms\n",
      "Wall time: 6.87 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Persist answers on a disk\n",
    "for idx, doc_id in enumerate(top_5_docs):\n",
    "    with open(f'answers/answer_{idx}', 'w+') as f:\n",
    "        f.write(df_full.iloc[doc_id].content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 0 doc_id: 94054\n",
      "Top 1 doc_id: 108355\n",
      "Top 2 doc_id: 90128\n",
      "Top 3 doc_id: 70823\n",
      "Top 4 doc_id: 109725\n"
     ]
    }
   ],
   "source": [
    "# Print top 5 articles\n",
    "for idx, doc_id in enumerate(top_5_docs):\n",
    "    print(f\"Top {idx} doc_id: {doc_id}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'In the office, one’s desk is one’s domain. But unlike your messy bedroom at home, this abode is on display whether you like it or not, especially in   open office plans. So what message does it send if your desk is stacked with paper, covered in “Star Trek” paraphernalia or bedecked with molding coffee cups? Experts say: not the best. “How we dress and how we maintain our work space are ways we communicate with people,” says Michelle Augenstein, founder of   consulting group  . “A messy desk is a barrier to communication. ” “A messy desk is a barrier to communication. ” It can even undermine your own credibility, she says. “It projects your work ethic to people, whether you like it or not. Are you known as the Lego lady or the ‘Star Wars’ aficionado first [by your  ]?” If so, you might want to disassemble the shrine instead of risking your personal quirks overshadowing your reputation as a hard worker. John Ore, head of product at   Business Insider, finds himself newly tidy at work. He recently went from a private office to the   chaotic and   open office plan. Yet the small space has somehow made him neater than ever. “Ironically, my current desk is probably about the cleanest I’ve ever had at work,” he says. “But it’s likely because we work in an open office environment and it’s not my own private office that I can clutter up with hockey paraphernalia. ” Now, he judges his  ’ desk clutter “only when it moves from clutter to gross, like food, a stale coffee mug or food wrappers,” he says. “Books piled high, reference materials  —   that I get. ” Joshua Gallaway, Ph. D. a senior research associate at the   in Hamilton Heights, falls in the clutter camp. But, he says, there’s a method to his madness. On his desk, he keeps “everything that I feel like I may need one day”  —   which, of course, means lots and lots of papers. “If I know it’s not going to stay in my brain, at least it’s on my desk and I know I [can] get it just in a second,” he says. He says his neighboring   makes a point to clean his own desk each night, but Gallaway chalks it up to a difference in philosophies. “He needs closure  —   I need everything at my fingertips. ” “When people walk by your office desk, they will judge you and your ability to take care of yourself. ” But while Gallaway is satisfied with his desktop situation, his   don’t always feel the same. “I do feel judged sometimes, but it doesn’t make me clean it up,” he says, reiterating the phrase that many workers defend their desks with: “It’s messy, but it’s actually really organized, it’s just that other people can’t tell. ” Sylvie di Giusto, founder of   thinks otherwise. If you want to be taken seriously, she says, keep your desk clean. In fact, she says it’s an issue that she addresses in all of her corporate training sessions and speaking engagements. “When people walk by your office desk, they will judge you and your ability to take care of yourself, your work tasks, your projects or their money and investments,” di Giusto says. “Is that fair or not? It doesn’t matter, because it happens automatically. ” If you want to be considered for the corner office  —   or any office  —   she says you must cultivate others’ perceptions of you meticulously. “Image management is micromanagement,” adds di Giusto. “It’s better to craft the way others are going to perceive you. ” That said, you don’t have to break out the white gloves. “I never advocate for the antiseptic,” Augenstein says. “We don’t want to cleanse our offices of everything that’s personal. Workplaces are made up of people. ” She recommends a few personal photos, possibly even plants. “Professionalism is about balance,” agrees di Giusto. “If you want to be perceived as leadership material, your office desk speaks volumes about that. ” Definitely off the table, and the desk: prescription medications, makeup, clothes, old food and an army of figurines. Say you follow the expert advice and you still find yourself messy? Research conducted at the University of Minnesota in 2013 showed that, surprisingly, subjects placed at cluttered desks came up with more creative ideas than those at a neater space. Share that with your neighboring    —   if you can see them over your belongings.'"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# One of the top 5 articles\n",
    "df_full.iloc[94054].content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
